@article{al-asadiInferenceVisualizationDNA,
  title = {Inference and Visualization of {{DNA}} Damage Patterns Using a Grade of Membership Model},
  author = {Al-Asadi, Hussein and Dey, Kushal K and Novembre, John and Stephens, Matthew},
  pages = {7},
  abstract = {Motivation: Quality control plays a major role in the analysis of ancient DNA (aDNA). One key step in this quality control is assessment of DNA damage: aDNA contains unique signatures of DNA damage that distinguish it from modern DNA, and so analyses of damage patterns can help confirm that DNA sequences obtained are from endogenous aDNA rather than from modern contamination. Predominant signatures of DNA damage include a high frequency of cytosine to thymine substitutions (C-to-T) at the ends of fragments, and elevated rates of purines (A \& G) before the 50 strand-breaks. Existing QC procedures help assess damage by simply plotting for each sample, the C-to-T mismatch rate along the read and the composition of bases before the 50 strand-breaks. Here we present a more flexible and comprehensive model-based approach to infer and visualize damage patterns in aDNA, implemented in an R package aRchaic. This approach is based on a ‘grade of membership’ model (also known as ‘admixture’ or ‘topic’ model) in which each sample has an estimated grade of membership in each of K damage profiles that are estimated from the data.},
  langid = {english},
  keywords = {adna,ancient dna,damage,damage pattern,mismatch},
  file = {/Users/michelsen/Zotero/storage/UXRKCH8R/Al-Asadi et al. - Inference and visualization of DNA damage patterns.pdf}
}

@thesis{al-nakeebMachineLearningTools2017,
  type = {phdthesis},
  title = {Machine {{Learning Tools}} for {{DNA Sequence Analysis}}},
  author = {Al-Nakeeb, Kosai},
  date = {2017-12},
  institution = {{Technical University of Copenhagen}},
  location = {{Department of Bio and Health Informatics}}
}

@article{bagerRiskHospitalisationAssociated2021,
  title = {Risk of Hospitalisation Associated with Infection with {{SARS-CoV-2}} Lineage {{B}}.1.1.7 in {{Denmark}}: An Observational Cohort Study},
  shorttitle = {Risk of Hospitalisation Associated with Infection with {{SARS-CoV-2}} Lineage {{B}}.1.1.7 in {{Denmark}}},
  author = {Bager, Peter and Wohlfahrt, Jan and Fonager, Jannik and Rasmussen, Morten and Albertsen, Mads and Michaelsen, Thomas Yssing and Møller, Camilla Holten and Ethelberg, Steen and Legarth, Rebecca and Button, Mia Sarah Fischer and Gubbels, Sophie and Voldstedlund, Marianne and Mølbak, Kåre and Skov, Robert Leo and Fomsgaard, Anders and Krause, Tyra Grove},
  date = {2021-11-01},
  journaltitle = {The Lancet Infectious Diseases},
  shortjournal = {The Lancet Infectious Diseases},
  volume = {21},
  number = {11},
  pages = {1507--1517},
  issn = {1473-3099},
  doi = {10.1016/S1473-3099(21)00290-5},
  url = {https://www.sciencedirect.com/science/article/pii/S1473309921002905},
  urldate = {2022-11-11},
  abstract = {Background The more infectious SARS-CoV-2 lineage B.1.1.7 rapidly spread in Europe after December, 2020, and a concern that B.1.1.7 could cause more severe disease has been raised. Taking advantage of Denmark's high RT-PCR testing and whole genome sequencing capacities, we used national health register data to assess the risk of COVID-19 hospitalisation in individuals infected with B.1.1.7 compared with those with other SARS-CoV-2 lineages. Methods We did an observational cohort study of all SARS-CoV-2-positive cases confirmed by RT-PCR in Denmark, sampled between Jan 1 and March 24, 2021, with 14 days of follow-up for COVID-19 hospitalisation. Cases were identified in the national COVID-19 surveillance system database, which includes data from the Danish Microbiology Database (RT-PCR test results), the Danish COVID-19 Genome Consortium, the National Patient Registry, the Civil Registration System, as well as other nationwide registers. Among all cases, COVID-19 hospitalisation was defined as first admission lasting longer than 12 h within 14 days of a sample with a positive RT-PCR result. The study population and main analysis were restricted to the proportion of cases with viral genome data. We calculated the risk ratio (RR) of admission according to infection with B.1.1.7 versus other co-existing lineages with a Poisson regression model with robust SEs, adjusted a priori for sex, age, calendar time, region, and comorbidities. The contribution of each covariate to confounding of the crude RR was evaluated afterwards by a stepwise forward inclusion. Findings Between Jan 1 and March 24, 2021, 50\,958 individuals with a positive SARS-CoV-2 test and at least 14 days of follow-up for hospitalisation were identified; 30\,572 (60·0\%) had genome data, of whom 10\,544 (34·5\%) were infected with B.1.1.7. 1944 (6·4\%) individuals had a COVID-19 hospitalisation and of these, 571 (29·4\%) had a B.1.1.7 infection and 1373 (70·6\%) had an infection with other SARS-CoV-2 lineages. Although the overall number of hospitalisations decreased during the study period, the proportion of individuals infected with B.1.1.7 increased from 3·5\% to 92·1\% per week. B.1.1.7 was associated with a crude RR of hospital admission of 0·79 (95\% CI 0·72–0·87; p{$<$}0·0001) and an adjusted RR of 1·42 (95\% CI 1·25–1·60; p{$<$}0·0001). The adjusted RR was increased in all strata of age and calendar period—the two covariates with the largest contribution to confounding of the crude RR. Interpretation Infection with SARS-CoV-2 lineage B.1.1.7 was associated with an increased risk of hospitalisation compared with that of other lineages in an analysis adjusted for covariates. The overall effect on hospitalisations in Denmark was lessened due to a strict lockdown, but our findings could support hospital preparedness and modelling of the projected impact of the epidemic in countries with uncontrolled spread of B.1.1.7. Funding None.},
  langid = {english},
  keywords = {corona,covid},
  file = {/Users/michelsen/Zotero/storage/5LV28UGM/bager2021.pdf.pdf;/Users/michelsen/Zotero/storage/6XZGIJYZ/Bager et al. - 2021 - Risk of hospitalisation associated with infection .pdf;/Users/michelsen/Zotero/storage/TCG623TX/S1473309921002905.html}
}

@article{briggsPatternsDamageGenomic2007,
  title = {Patterns of Damage in Genomic {{DNA}} Sequences from a {{Neandertal}}},
  author = {Briggs, Adrian W. and Stenzel, Udo and Johnson, Philip L. F. and Green, Richard E. and Kelso, Janet and Prüfer, Kay and Meyer, Matthias and Krause, Johannes and Ronan, Michael T. and Lachmann, Michael and Pääbo, Svante},
  date = {2007-09-11},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {104},
  number = {37},
  eprint = {17715061},
  eprinttype = {pmid},
  pages = {14616--14621},
  issn = {0027-8424},
  doi = {10.1073/pnas.0704665104},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1976210/},
  urldate = {2019-03-04},
  abstract = {High-throughput direct sequencing techniques have recently opened the possibility to sequence genomes from Pleistocene organisms. Here we analyze DNA sequences determined from a Neandertal, a mammoth, and a cave bear. We show that purines are overrepresented at positions adjacent to the breaks in the ancient DNA, suggesting that depurination has contributed to its degradation. We furthermore show that substitutions resulting from miscoding cytosine residues are vastly overrepresented in the DNA sequences and drastically clustered in the ends of the molecules, whereas other substitutions are rare. We present a model where the observed substitution patterns are used to estimate the rate of deamination of cytosine residues in single- and double-stranded portions of the DNA, the length of single-stranded ends, and the frequency of nicks. The results suggest that reliable genome sequences can be obtained from Pleistocene organisms.},
  pmcid = {PMC1976210},
  keywords = {adna,ancient dna,damage,damage pattern,mismatch},
  file = {/Users/michelsen/Zotero/storage/8RS8X78U/Briggs et al. - 2007 - Patterns of damage in genomic DNA sequences from a.pdf}
}

@article{daleyModelingGenomeCoverage2014,
  title = {Modeling Genome Coverage in Single-Cell Sequencing},
  author = {Daley, Timothy and Smith, Andrew D.},
  date = {2014-11-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {30},
  number = {22},
  eprint = {25107873},
  eprinttype = {pmid},
  pages = {3159--3165},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btu540},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4221128/},
  urldate = {2019-10-01},
  abstract = {Motivation: Single-cell DNA sequencing is necessary for examining genetic variation at the cellular level, which remains hidden in bulk sequencing experiments. But because they begin with such small amounts of starting material, the amount of information that is obtained from single-cell sequencing experiment is highly sensitive to the choice of protocol employed and variability in library preparation. In particular, the fraction of the genome represented in single-cell sequencing libraries exhibits extreme variability due to quantitative biases in amplification and loss of genetic material., Results: We propose a method to predict the genome coverage of a deep sequencing experiment using information from an initial shallow sequencing experiment mapped to a reference genome. The observed coverage statistics are used in a non-parametric empirical Bayes Poisson model to estimate the gain in coverage from deeper sequencing. This approach allows researchers to know statistical features of deep sequencing experiments without actually sequencing deeply, providing a basis for optimizing and comparing single-cell sequencing protocols or screening libraries., Availability and implementation: The method is available as part of the preseq software package. Source code is available at http://smithlabresearch.org/preseq., Contact: andrewds@usc.edu, Supplementary information: Supplementary material is available at Bioinformatics online.},
  pmcid = {PMC4221128},
  file = {/Users/michelsen/Zotero/storage/6ZK3XXI9/Daley and Smith - 2014 - Modeling genome coverage in single-cell sequencing.pdf}
}

@article{flagelUnreasonableEffectivenessConvolutional2018,
  title = {The {{Unreasonable Effectiveness}} of {{Convolutional Neural Networks}} in {{Population Genetic Inference}}},
  author = {Flagel, Lex and Brandvain, Yaniv J and Schrider, Daniel R},
  date = {2018-11-27},
  journaltitle = {bioRxiv},
  doi = {10.1101/336073},
  url = {http://biorxiv.org/lookup/doi/10.1101/336073},
  urldate = {2019-01-03},
  abstract = {Population-scale genomic datasets have given researchers incredible amounts of information from which to infer evolutionary histories. Concomitant with this flood of data, theoretical and methodological advances have sought to extract information from genomic sequences to infer demographic events such as population size changes and gene flow among closely related populations/species, construct recombination maps, and uncover loci underlying recent adaptation. To date most methods make use of only one or a few summaries of the input sequences and therefore ignore potentially useful information encoded in the data. The most sophisticated of these approaches involve likelihood calculations, which require theoretical advances for each new problem, and often focus on a single aspect of the data (e.g. only allele frequency information) in the interest of mathematical and computational tractability. Directly interrogating the entirety of the input sequence data in a likelihood-free manner would thus offer a fruitful alternative. Here we accomplish this by representing DNA sequence alignments as images and using a class of deep learning methods called convolutional neural networks (CNNs) to make population genetic inferences from these images. We apply CNNs to a number of evolutionary questions and find that they frequently match or exceed the accuracy of current methods. Importantly, we show that CNNs perform accurate evolutionary model selection and parameter estimation, even on problems that have not received detailed theoretical treatments. Thus, when applied to population genetic alignments, CNN are capable of outperforming expert-derived statistical methods, and offer a new path forward in cases where no likelihood approach exists.},
  langid = {english},
  file = {/Users/michelsen/Zotero/storage/74GZM445/Flagel et al. - 2018 - The Unreasonable Effectiveness of Convolutional Ne.pdf}
}

@article{heltbergSpatialHeterogeneityAffects2022a,
  title = {Spatial Heterogeneity Affects Predictions from Early-Curve Fitting of Pandemic Outbreaks: A Case Study Using Population Data from {{Denmark}}},
  author = {Heltberg, Mathias Spliid and Michelsen, Christian and Martiny, Emil S. and Christensen, Lasse Engbo and Jensen, Mogens H. and Halasa, Tariq and Petersen, Troels C.},
  date = {2022-09-14},
  journaltitle = {Royal Society Open Science},
  volume = {9},
  number = {9},
  publisher = {{TheRoyal Society Publishing}},
  issn = {2054-5703},
  doi = {10.1098/rsos.220018},
  abstract = {The modelling of pandemics has become a critical aspect in modern society. Even though artificial intelligence can help the forecast, the implementation of ordinary differential equations which estimate the time development in the number of susceptible, (exposed), infected and recovered (SIR/SEIR) individuals is still important in order to understand the stage of the pandemic. These models are based on simplified assumptions which constitute approximations, but to what extent this are erroneous is not understood since many factors can affect the development. In this paper, we introduce an agent-based model including spatial clustering and heterogeneities in connectivity and infection strength. Based on Danish population data, we estimate how this impacts the early prediction of a pandemic and compare this to the long-term development. Our results show that early phase SEIR model predictions overestimate the peak number of infected and the equilibrium level by at least a factor of two. These results are robust to variations of parameters influencing connection distances and independent of the distribution of infection rates.},
  langid = {english},
  keywords = {agent-based modelling,COVID-19,fitting,pandemics,spatial heterogenity}
}

@article{jonssonMapDamage2FastApproximate2013,
  title = {{{mapDamage2}}.0: Fast Approximate {{Bayesian}} Estimates of Ancient {{DNA}} Damage Parameters},
  shorttitle = {{{mapDamage2}}.0},
  author = {Jónsson, Hákon and Ginolhac, Aurélien and Schubert, Mikkel and Johnson, Philip L. F. and Orlando, Ludovic},
  date = {2013-07-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {29},
  number = {13},
  eprint = {23613487},
  eprinttype = {pmid},
  pages = {1682--1684},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btt193},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3694634/},
  urldate = {2019-01-24},
  abstract = {Motivation: Ancient DNA (aDNA) molecules in fossilized bones and teeth, coprolites, sediments, mummified specimens and museum collections represent fantastic sources of information for evolutionary biologists, revealing the agents of past epidemics and the dynamics of past populations. However, the analysis of aDNA generally faces two major issues. Firstly, sequences consist of a mixture of endogenous and various exogenous backgrounds, mostly microbial. Secondly, high nucleotide misincorporation rates can be observed as a result of severe post-mortem DNA damage. Such misincorporation patterns are instrumental to authenticate ancient sequences versus modern contaminants. We recently developed the user-friendly mapDamage package that identifies such patterns from next-generation sequencing (NGS) sequence datasets. The absence of formal statistical modeling of the DNA damage process, however, precluded rigorous quantitative comparisons across samples., Results: Here, we describe mapDamage 2.0 that extends the original features of mapDamage by incorporating a statistical model of DNA damage. Assuming that damage events depend only on sequencing position and post-mortem deamination, our Bayesian statistical framework provides estimates of four key features of aDNA molecules: the average length of overhangs (λ), nick frequency (ν) and cytosine deamination rates in both double-stranded regions () and overhangs (). Our model enables rescaling base quality scores according to their probability of being damaged. mapDamage 2.0 handles NGS datasets with ease and is compatible with a wide range of DNA library protocols., Availability: mapDamage 2.0 is available at ginolhac.github.io/mapDamage/ as a Python package and documentation is maintained at the Centre for GeoGenetics Web site (geogenetics.ku.dk/publications/mapdamage2.0/)., Contact: jonsson.hakon@gmail.com, Supplementary information: Supplementary data are available at Bioinformatics online.},
  pmcid = {PMC3694634},
  keywords = {adna,ancient,dna,mapdamage},
  file = {/Users/michelsen/Zotero/storage/SHHXN72V/Jónsson et al. - 2013 - mapDamage2.0 fast approximate Bayesian estimates .pdf}
}

@unpublished{killoranGeneratingDesigningDNA2017,
  title = {Generating and Designing {{DNA}} with Deep Generative Models},
  author = {Killoran, Nathan and Lee, Leo J. and Delong, Andrew and Duvenaud, David and Frey, Brendan J.},
  date = {2017-12-17},
  eprint = {1712.06148},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  url = {http://arxiv.org/abs/1712.06148},
  urldate = {2019-10-01},
  abstract = {We propose generative neural network methods to generate DNA sequences and tune them to have desired properties. We present three approaches: creating synthetic DNA sequences using a generative adversarial network; a DNA-based variant of the activation maximization ("deep dream") design method; and a joint procedure which combines these two approaches together. We show that these tools capture important structures of the data and, when applied to designing probes for protein binding microarrays, allow us to generate new sequences whose properties are estimated to be superior to those found in the training data. We believe that these results open the door for applying deep generative models to advance genomics research.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,dna,GAN,Quantitative Biology - Genomics,Statistics - Machine Learning},
  file = {/Users/michelsen/Zotero/storage/H96ZJIXN/Killoran et al. - 2017 - Generating and designing DNA with deep generative .pdf;/Users/michelsen/Zotero/storage/4ICGP6CQ/1712.html}
}

@article{korneliussenANGSDAnalysisNext2014,
  title = {{{ANGSD}}: {{Analysis}} of {{Next Generation Sequencing Data}}},
  shorttitle = {{{ANGSD}}},
  author = {Korneliussen, Thorfinn Sand and Albrechtsen, Anders and Nielsen, Rasmus},
  date = {2014-11-25},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {15},
  number = {1},
  pages = {356},
  issn = {1471-2105},
  doi = {10.1186/s12859-014-0356-4},
  url = {https://doi.org/10.1186/s12859-014-0356-4},
  urldate = {2019-01-03},
  abstract = {High-throughput DNA sequencing technologies are generating vast amounts of data. Fast, flexible and memory efficient implementations are needed in order to facilitate analyses of thousands of samples simultaneously.},
  file = {/Users/michelsen/Zotero/storage/RVY8WNI4/Korneliussen et al. - 2014 - ANGSD Analysis of Next Generation Sequencing Data.pdf;/Users/michelsen/Zotero/storage/4QCYKUQB/s12859-014-0356-4.html}
}

@article{liInferenceHumanPopulation2011,
  title = {Inference of Human Population History from Individual Whole-Genome Sequences},
  author = {Li, Heng and Durbin, Richard},
  date = {2011-07},
  journaltitle = {Nature},
  volume = {475},
  number = {7357},
  pages = {493--496},
  issn = {1476-4687},
  doi = {10.1038/nature10231},
  url = {https://www.nature.com/articles/nature10231},
  urldate = {2019-01-03},
  abstract = {The history of human population size is important for understanding human evolution. Various studies1,2,3,4,5 have found evidence for a founder event (bottleneck) in East Asian and European populations, associated with the human dispersal out-of-Africa event around 60 thousand years (kyr) ago. However, these studies have had to assume simplified demographic models with few parameters, and they do not provide a precise date for the start and stop times of the bottleneck. Here, with fewer assumptions on population size changes, we present a more detailed history of human population sizes between approximately ten thousand and a million years ago, using the pairwise sequentially Markovian coalescent model applied to the complete diploid genome sequences of a Chinese male (YH)6, a Korean male (SJK)7, three European individuals (J. C. Venter8, NA12891 and NA12878 (ref. 9)) and two Yoruba males (NA18507 (ref. 10) and NA19239). We infer that European and Chinese populations had very similar population-size histories before 10–20 kyr ago. Both populations experienced a severe bottleneck 10–60 kyr ago, whereas African populations experienced a milder bottleneck from which they recovered earlier. All three populations have an elevated effective population size between 60 and 250 kyr ago, possibly due to population substructure11. We also infer that the differentiation of genetically modern humans may have started as early as 100–120 kyr ago12, but considerable genetic exchanges may still have occurred until 20–40 kyr ago.},
  langid = {english},
  file = {/Users/michelsen/Zotero/storage/F6P22Y3N/Li and Durbin - 2011 - Inference of human population history from individ.pdf;/Users/michelsen/Zotero/storage/LLCR4JBW/nature10231.html}
}

@article{makComparativePerformanceBGISEQ5002017,
  title = {Comparative Performance of the {{BGISEQ-500}} vs {{Illumina HiSeq2500}} Sequencing Platforms for Palaeogenomic Sequencing},
  author = {Mak, Sarah Siu Tze and Gopalakrishnan, Shyam and Carøe, Christian and Geng, Chunyu and Liu, Shanlin and Sinding, Mikkel-Holger S and Kuderna, Lukas F K and Zhang, Wenwei and Fu, Shujin and Vieira, Filipe G and Germonpré, Mietje and Bocherens, Hervé and Fedorov, Sergey and Petersen, Bent and Sicheritz-Pontén, Thomas and Marques-Bonet, Tomas and Zhang, Guojie and Jiang, Hui and Gilbert, M Thomas P},
  date = {2017-06-26},
  journaltitle = {GigaScience},
  shortjournal = {Gigascience},
  volume = {6},
  number = {8},
  eprint = {28854615},
  eprinttype = {pmid},
  pages = {1--13},
  issn = {2047-217X},
  doi = {10.1093/gigascience/gix049},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570000/},
  urldate = {2019-01-03},
  abstract = {Ancient DNA research has been revolutionized following development of next-generation sequencing platforms. Although a number of such platforms have been applied to ancient DNA samples, the Illumina series are the dominant choice today, mainly because of high production capacities and short read production. Recently a potentially attractive alternative platform for palaeogenomic data generation has been developed, the BGISEQ-500, whose sequence output are comparable with the Illumina series. In this study, we modified the standard BGISEQ-500 library preparation specifically for use on degraded DNA, then directly compared the sequencing performance and data quality of the BGISEQ-500 to the Illumina HiSeq2500 platform on DNA extracted from 8 historic and ancient dog and wolf samples. The data generated were largely comparable between sequencing platforms, with no statistically significant difference observed for parameters including level (P = 0.371) and average sequence length (P = 0718) of endogenous nuclear DNA, sequence GC content (P = 0.311), double-stranded DNA damage rate (v. 0.309), and sequence clonality (P = 0.093). Small significant differences were found in single-strand DNA damage rate (δS; slightly lower for the BGISEQ-500, P = 0.011) and the background rate of difference from the reference genome (θ; slightly higher for BGISEQ-500, P = 0.012). This may result from the differences in amplification cycles used to polymerase chain reaction–amplify the libraries. A significant difference was also observed in the mitochondrial DNA percentages recovered (P = 0.018), although we believe this is likely a stochastic effect relating to the extremely low levels of mitochondria that were sequenced from 3 of the samples with overall very low levels of endogenous DNA. Although we acknowledge that our analyses were limited to animal material, our observations suggest that the BGISEQ-500 holds the potential to represent a valid and potentially valuable alternative platform for palaeogenomic data generation that is worthy of future exploration by those interested in the sequencing and analysis of degraded DNA.},
  pmcid = {PMC5570000},
  file = {/Users/michelsen/Zotero/storage/X3XQ9ILX/Mak et al. - 2017 - Comparative performance of the BGISEQ-500 vs Illum.pdf}
}

@article{meyerNuclearDNASequences2016a,
  title = {Nuclear {{DNA}} Sequences from the {{Middle Pleistocene Sima}} de Los {{Huesos}} Hominins},
  author = {Meyer, Matthias and Arsuaga, Juan-Luis and de Filippo, Cesare and Nagel, Sarah and Aximu-Petri, Ayinuer and Nickel, Birgit and Martínez, Ignacio and Gracia, Ana and de Castro, José María Bermúdez and Carbonell, Eudald and Viola, Bence and Kelso, Janet and Prüfer, Kay and Pääbo, Svante},
  options = {useprefix=true},
  date = {2016-03},
  journaltitle = {Nature},
  volume = {531},
  number = {7595},
  pages = {504--507},
  issn = {1476-4687},
  doi = {10.1038/nature17405},
  url = {https://www.nature.com/articles/nature17405},
  urldate = {2019-10-01},
  abstract = {A unique assemblage of 28 hominin individuals, found in Sima de los Huesos in the Sierra de Atapuerca in Spain, has recently been dated to approximately 430,000 years ago1. An interesting question is how these Middle Pleistocene hominins were related to those who lived in the Late Pleistocene epoch, in particular to Neanderthals in western Eurasia and to Denisovans, a sister group of Neanderthals so far known only from southern Siberia. While the Sima de los Huesos hominins share some derived morphological features with Neanderthals, the mitochondrial genome retrieved from one individual from Sima de los Huesos is more closely related to the mitochondrial DNA of Denisovans than to that of Neanderthals2. However, since the mitochondrial DNA does not reveal the full picture of relationships among populations, we have investigated DNA preservation in several individuals found at Sima de los Huesos. Here we recover nuclear DNA sequences from two specimens, which show that the Sima de los Huesos hominins were related to Neanderthals rather than to Denisovans, indicating that the population divergence between Neanderthals and Denisovans predates 430,000 years ago. A mitochondrial DNA recovered from one of the specimens shares the previously described relationship to Denisovan mitochondrial DNAs, suggesting, among other possibilities, that the mitochondrial DNA gene pool of Neanderthals turned over later in their history.},
  langid = {english},
  file = {/Users/michelsen/Zotero/storage/4J452WUH/Meyer et al. - 2016 - Nuclear DNA sequences from the Middle Pleistocene .pdf;/Users/michelsen/Zotero/storage/8STA35B9/nature17405.html}
}

@unpublished{ngDna2vecConsistentVector2017,
  title = {Dna2vec: {{Consistent}} Vector Representations of Variable-Length k-Mers},
  shorttitle = {Dna2vec},
  author = {Ng, Patrick},
  date = {2017-01-23},
  eprint = {1701.06279},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  url = {http://arxiv.org/abs/1701.06279},
  urldate = {2019-10-01},
  abstract = {One of the ubiquitous representation of long DNA sequence is dividing it into shorter k-mer components. Unfortunately, the straightforward vector encoding of k-mer as a one-hot vector is vulnerable to the curse of dimensionality. Worse yet, the distance between any pair of one-hot vectors is equidistant. This is particularly problematic when applying the latest machine learning algorithms to solve problems in biological sequence analysis. In this paper, we propose a novel method to train distributed representations of variable-length k-mers. Our method is based on the popular word embedding model word2vec, which is trained on a shallow two-layer neural network. Our experiments provide evidence that the summing of dna2vec vectors is akin to nucleotides concatenation. We also demonstrate that there is correlation between Needleman-Wunsch similarity score and cosine similarity of dna2vec vectors.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,dna,dna2vec,embedding,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/Users/michelsen/Zotero/storage/YZQUSFFJ/Ng - 2017 - dna2vec Consistent vector representations of vari.pdf;/Users/michelsen/Zotero/storage/CHA7Y2FC/1701.html}
}

@article{nielsenTracingPeoplingWorld2017,
  title = {Tracing the Peopling of the World through Genomics},
  author = {Nielsen, Rasmus and Akey, Joshua M. and Jakobsson, Mattias and Pritchard, Jonathan K. and Tishkoff, Sarah and Willerslev, Eske},
  date = {2017-01},
  journaltitle = {Nature},
  volume = {541},
  number = {7637},
  pages = {302--310},
  issn = {1476-4687},
  doi = {10.1038/nature21347},
  url = {https://www.nature.com/articles/nature21347},
  urldate = {2019-01-03},
  abstract = {Advances in the sequencing and the analysis of the genomes of both modern and ancient peoples have facilitated a number of breakthroughs in our understanding of human evolutionary history. These include the discovery of interbreeding between anatomically modern humans and extinct hominins; the development of an increasingly detailed description of the complex dispersal of modern humans out of Africa and their population expansion worldwide; and the characterization of many of the genetic adaptions of humans to local environmental conditions. Our interpretation of the evolutionary history and adaptation of humans is being transformed by analyses of these new genomic data.},
  langid = {english},
  file = {/Users/michelsen/Zotero/storage/MQ5Z6BM8/Nielsen et al. - 2017 - Tracing the peopling of the world through genomics.pdf;/Users/michelsen/Zotero/storage/K8I2HX53/nature21347.html}
}

@article{ramageHiddenMarkovModels2007,
  title = {Hidden {{Markov Models Fundamentals}}},
  author = {Ramage, Daniel},
  date = {2007-12-01},
  journaltitle = {CS229 Section Notes},
  pages = {13},
  langid = {english},
  keywords = {hidden,hmm,markov},
  file = {/Users/michelsen/Zotero/storage/QJEW5BQC/Ramage - Hidden Markov Models Fundamentals.pdf}
}

@article{scargleSTUDIESASTRONOMICALTIME2013a,
  title = {{{STUDIES IN ASTRONOMICAL TIME SERIES ANALYSIS}}. {{VI}}. {{BAYESIAN BLOCK REPRESENTATIONS}}},
  author = {Scargle, Jeffrey D. and Norris, Jay P. and Jackson, Brad and Chiang, James},
  date = {2013-02-04},
  journaltitle = {The Astrophysical Journal},
  volume = {764},
  number = {2},
  pages = {167},
  issn = {0004-637X, 1538-4357},
  doi = {10.1088/0004-637X/764/2/167},
  url = {http://stacks.iop.org/0004-637X/764/i=2/a=167?key=crossref.0539dc6f37f29e250567031865ebbe9a},
  urldate = {2019-01-03},
  langid = {english},
  file = {/Users/michelsen/Zotero/storage/4A3PNMCM/Scargle et al. - 2013 - STUDIES IN ASTRONOMICAL TIME SERIES ANALYSIS. VI. .pdf}
}

@article{schriderSupervisedMachineLearning2018,
  title = {Supervised {{Machine Learning}} for {{Population Genetics}}: {{A New Paradigm}}},
  shorttitle = {Supervised {{Machine Learning}} for {{Population Genetics}}},
  author = {Schrider, Daniel R. and Kern, Andrew D.},
  date = {2018-04-01},
  journaltitle = {Trends in Genetics},
  shortjournal = {Trends in Genetics},
  volume = {34},
  number = {4},
  pages = {301--312},
  issn = {0168-9525},
  doi = {10.1016/j.tig.2017.12.005},
  url = {http://www.sciencedirect.com/science/article/pii/S0168952517302251},
  urldate = {2019-01-03},
  abstract = {As population genomic datasets grow in size, researchers are faced with the daunting task of making sense of a flood of information. To keep pace with this explosion of data, computational methodologies for population genetic inference are rapidly being developed to best utilize genomic sequence data. In this review we discuss a new paradigm that has emerged in computational population genomics: that of supervised machine learning (ML). We review the fundamentals of ML, discuss recent applications of supervised ML to population genetics that outperform competing methods, and describe promising future directions in this area. Ultimately, we argue that supervised ML is an important and underutilized tool that has considerable potential for the world of evolutionary genomics.},
  file = {/Users/michelsen/Zotero/storage/Q6SCUPCV/Schrider and Kern - 2018 - Supervised Machine Learning for Population Genetic.pdf;/Users/michelsen/Zotero/storage/FYU4DRC2/S0168952517302251.html}
}

@article{schubertImprovingAncientDNA2012,
  title = {Improving Ancient {{DNA}} Read Mapping against Modern Reference Genomes},
  author = {Schubert, Mikkel and Ginolhac, Aurelien and Lindgreen, Stinus and Thompson, John F and AL-Rasheid, Khaled AS and Willerslev, Eske and Krogh, Anders and Orlando, Ludovic},
  date = {2012-05-10},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {13},
  eprint = {22574660},
  eprinttype = {pmid},
  pages = {178},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-13-178},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3468387/},
  urldate = {2019-01-03},
  abstract = {Background Next-Generation Sequencing has revolutionized our approach to ancient DNA (aDNA) research, by providing complete genomic sequences of ancient individuals and extinct species. However, the recovery of genetic material from long-dead organisms is still complicated by a number of issues, including post-mortem DNA damage and high levels of environmental contamination. Together with error profiles specific to the type of sequencing platforms used, these specificities could limit our ability to map sequencing reads against modern reference genomes and therefore limit our ability to identify endogenous ancient reads, reducing the efficiency of shotgun sequencing aDNA. Results In this study, we compare different computational methods for improving the accuracy and sensitivity of aDNA sequence identification, based on shotgun sequencing reads recovered from Pleistocene horse extracts using Illumina GAIIx and Helicos Heliscope platforms. We show that the performance of the Burrows Wheeler Aligner (BWA), that has been developed for mapping of undamaged sequencing reads using platforms with low rates of indel-types of sequencing errors, can be employed at acceptable run-times by modifying default parameters in a platform-specific manner. We also examine if trimming likely damaged positions at read ends can increase the recovery of genuine aDNA fragments and if accurate identification of human contamination can be achieved using a strategy previously suggested based on best hit filtering. We show that combining our different mapping and filtering approaches can increase the number of high-quality endogenous hits recovered by up to 33\%. Conclusions We have shown that Illumina and Helicos sequences recovered from aDNA extracts could not be aligned to modern reference genomes with the same efficiency unless mapping parameters are optimized for the specific types of errors generated by these platforms and by post-mortem DNA damage. Our findings have important implications for future aDNA research, as we define mapping guidelines that improve our ability to identify genuine aDNA sequences, which in turn could improve the genotyping accuracy of ancient specimens. Our framework provides a significant improvement to the standard procedures used for characterizing ancient genomes, which is challenged by contamination and often low amounts of DNA material.},
  pmcid = {PMC3468387},
  file = {/Users/michelsen/Zotero/storage/PFBHIWHF/Schubert et al. - 2012 - Improving ancient DNA read mapping against modern .pdf}
}

@article{sheehanDeepLearningPopulation2016,
  title = {Deep {{Learning}} for {{Population Genetic Inference}}},
  author = {Sheehan, Sara and Song, Yun S.},
  date = {2016-03-28},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {3},
  pages = {e1004845},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004845},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004845},
  urldate = {2019-01-03},
  abstract = {Given genomic variation data from multiple individuals, computing the likelihood of complex population genetic models is often infeasible. To circumvent this problem, we introduce a novel likelihood-free inference framework by applying deep learning, a powerful modern technique in machine learning. Deep learning makes use of multilayer neural networks to learn a feature-based function from the input (e.g., hundreds of correlated summary statistics of data) to the output (e.g., population genetic parameters of interest). We demonstrate that deep learning can be effectively employed for population genetic inference and learning informative features of data. As a concrete application, we focus on the challenging problem of jointly inferring natural selection and demography (in the form of a population size change history). Our method is able to separate the global nature of demography from the local nature of selection, without sequential steps for these two factors. Studying demography and selection jointly is motivated by Drosophila, where pervasive selection confounds demographic analysis. We apply our method to 197 African Drosophila melanogaster genomes from Zambia to infer both their overall demography, and regions of their genome under selection. We find many regions of the genome that have experienced hard sweeps, and fewer under selection on standing variation (soft sweep) or balancing selection. Interestingly, we find that soft sweeps and balancing selection occur more frequently closer to the centromere of each chromosome. In addition, our demographic inference suggests that previously estimated bottlenecks for African Drosophila melanogaster are too extreme.},
  langid = {english},
  keywords = {Drosophila melanogaster,Effective population size,Genomics statistics,Invertebrate genomics,Natural selection,Neural networks,Population genetics,Population size},
  file = {/Users/michelsen/Zotero/storage/PE2B8UNQ/Sheehan and Song - 2016 - Deep Learning for Population Genetic Inference.pdf;/Users/michelsen/Zotero/storage/Z8WHRA3J/article.html}
}

@article{slatkinStatisticalMethodsAnalyzing2016,
  title = {Statistical Methods for Analyzing Ancient {{DNA}} from Hominins},
  author = {Slatkin, Montgomery},
  date = {2016-12-01},
  journaltitle = {Current Opinion in Genetics \& Development},
  shortjournal = {Current Opinion in Genetics \& Development},
  series = {Genetics of Human Origin},
  volume = {41},
  pages = {72--76},
  issn = {0959-437X},
  doi = {10.1016/j.gde.2016.08.004},
  url = {http://www.sciencedirect.com/science/article/pii/S0959437X16301083},
  urldate = {2019-01-03},
  abstract = {In the past few years, the number of autosomal DNA sequences from human fossils has grown explosively and numerous partial or complete sequences are available from our closest relatives, Neanderthal and Denisovans. I review commonly used statistical methods applied to these sequences. These methods fall into three broad classes: methods for estimating levels of contamination, descriptive methods, and methods based on population genetic models. The latter two classes are largely methods developed for the analysis of present-day genomic data. When they are applied to ancient DNA (aDNA), they usually ignore the time dimension. A few methods, particularly those concerned with inferring something about selection or ancestor–descendant relationships, take explicit account of the ages of aDNA samples.},
  file = {/Users/michelsen/Zotero/storage/PDHNVEMZ/Slatkin - 2016 - Statistical methods for analyzing ancient DNA from.pdf;/Users/michelsen/Zotero/storage/NYGSH49N/S0959437X16301083.html}
}

@article{spencerAuthenticityAncientDNAResults2004,
  title = {Authenticity of {{Ancient-DNA Results}}: {{A Statistical Approach}}},
  shorttitle = {Authenticity of {{Ancient-DNA Results}}},
  author = {Spencer, Matthew and Howe, Christopher J.},
  date = {2004-08},
  journaltitle = {American Journal of Human Genetics},
  shortjournal = {Am J Hum Genet},
  volume = {75},
  number = {2},
  eprint = {15199524},
  eprinttype = {pmid},
  pages = {240--250},
  issn = {0002-9297},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1216058/},
  urldate = {2019-01-03},
  abstract = {Although there have been several papers recommending appropriate experimental designs for ancient-DNA studies, there have been few attempts at statistical analysis. We assume that we cannot decide whether a result is authentic simply by examining the sequence (e.g., when working with humans and domestic animals). We use a maximum-likelihood approach to estimate the probability that a positive result from a sample is (either partly or entirely) an amplification of DNA that was present in the sample before the experiment began. Our method is useful in two situations. First, we can decide in advance how many samples will be needed to achieve a given level of confidence. For example, to be almost certain (95\% confidence interval 0.96–1.00, maximum-likelihood estimate 1.00) that a positive result comes, at least in part, from DNA present before the experiment began, we need to analyze at least five samples and controls, even if all samples and no negative controls yield positive results. Second, we can decide how much confidence to place in results that have been obtained already, whether or not there are positive results from some controls. For example, the risk that at least one negative control yields a positive result increases with the size of the experiment, but the effects of occasional contamination are less severe in large experiments.},
  pmcid = {PMC1216058},
  file = {/Users/michelsen/Zotero/storage/QSS4IU3A/Spencer and Howe - 2004 - Authenticity of Ancient-DNA Results A Statistical.pdf}
}

@article{suDetectionIdentityDescent2012,
  title = {Detection of Identity by Descent Using Next-Generation Whole Genome Sequencing Data},
  author = {Su, Shu-Yi and Kasberger, Jay and Baranzini, Sergio and Byerley, William and Liao, Wilson and Oksenberg, Jorge and Sherr, Elliott and Jorgenson, Eric},
  date = {2012-06-06},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {13},
  eprint = {22672699},
  eprinttype = {pmid},
  pages = {121},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-13-121},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3403908/},
  urldate = {2019-01-03},
  abstract = {Background Identity by descent (IBD) has played a fundamental role in the discovery of genetic loci underlying human diseases. Both pedigree-based and population-based linkage analyses rely on estimating recent IBD, and evidence of ancient IBD can be used to detect population structure in genetic association studies. Various methods for detecting IBD, including those implemented in the soft- ware programs fastIBD and GERMLINE, have been developed in the past several years using population genotype data from microarray platforms. Now, next-generation DNA sequencing data is becoming increasingly available, enabling the comprehensive analysis of genomes, in- cluding identifying rare variants. These sequencing data may provide an opportunity to detect IBD with higher resolution than previously possible, potentially enabling the detection of disease causing loci that were previously undetectable with sparser genetic data. Results Here, we investigate how different levels of variant coverage in sequencing and microarray genotype data influences the resolution at which IBD can be detected. This includes microarray genotype data from the WTCCC study, denser genotype data from the HapMap Project, low coverage sequencing data from the 1000 Genomes Project, and deep coverage complete genome data from our own projects. With high power (78\%), we can detect segments of length 0.4 cM or larger using fastIBD and GERMLINE in sequencing data. This compares to similar power to detect segments of length 1.0 cM or higher with microarray genotype data. We find that GERMLINE has slightly higher power than fastIBD for detecting IBD segments using sequencing data, but also has a much higher false positive rate. Conclusion We further quantify the effect of variant density, conditional on genetic map length, on the power to resolve IBD segments. These investigations into IBD resolution may help guide the design of future next generation sequencing studies that utilize IBD, including family-based association studies, association studies in admixed populations, and homozygosity mapping studies.},
  pmcid = {PMC3403908},
  file = {/Users/michelsen/Zotero/storage/HXAXM6CV/Su et al. - 2012 - Detection of identity by descent using next-genera.pdf}
}

@article{yoonHiddenMarkovModels2009,
  title = {Hidden {{Markov Models}} and Their {{Applications}} in {{Biological Sequence Analysis}}},
  author = {Yoon, Byung-Jun},
  date = {2009-09},
  journaltitle = {Current Genomics},
  shortjournal = {Curr Genomics},
  volume = {10},
  number = {6},
  eprint = {20190955},
  eprinttype = {pmid},
  pages = {402--415},
  issn = {1389-2029},
  doi = {10.2174/138920209789177575},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2766791/},
  urldate = {2019-01-03},
  abstract = {Hidden Markov models (HMMs) have been extensively used in biological sequence analysis. In this paper, we give a tutorial review of HMMs and their applications in a variety of problems in molecular biology. We especially focus on three types of HMMs: the profile-HMMs, pair-HMMs, and context-sensitive HMMs. We show how these HMMs can be used to solve various sequence analysis problems, such as pairwise and multiple sequence alignments, gene annotation, classification, similarity search, and many others.},
  pmcid = {PMC2766791},
  file = {/Users/michelsen/Zotero/storage/ZCIR5LBL/Yoon - 2009 - Hidden Markov Models and their Applications in Bio.pdf}
}

